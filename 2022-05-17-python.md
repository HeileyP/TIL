# 데이터수집

**KEYWORD : html, css, requests, BeautifulSoup, get, post, api, 저작권, robots.txt, 로봇배제표준, html parser, lxml, euc-kr, cp949, tqdm(progress bar)**

데이터를 가져올 수 있는 방식
* GET - url
* POST - json
* HEAD
* PUT

URL 경로의 데이터를 수집하기 위한 방법
<ol>
  <li>웹의 개발자모드에서 Headers의 Request Method를 확인한다.</li>
  <li>requests를 통해 브라우저 접근이라는 것을 의미하는 hearders 옵션인 User-Agent를 확인한다.</li>
</ol>

requests로 HTTP 요청을 보냈을 때 받는 응답
* 200(OK)
* 404(페이지를 찾을 수 없음 Not Found)

오래 걸리는 작업의 진행상황을 시각화하는 도구
* tqdm
<br>

### 회기
---
* fact : Jupyter notebook으로 웹스크래핑 실습을 했다.
* feel : 함수를 만드는 부분에서 이해가 안되는 부분이 있었다. 복습하면서 천천히 익히니까 이해가 되었는데, pandas에서 read_html로 불러왔을 때 바로 테이블이 만들어지는 것이 신기했다. 파이썬에서 타입은 리스트이지만 html table태그의 값을 불러오니 인덱션 값으로 데이터프레임을 간단하게 만들 수 있었다.
* insight : 함수나 클래스는 이해가 잘 안됐는데 깃헙에 웹스크래핑 리포지토리를 만들어서 연습해보려고 한다.
